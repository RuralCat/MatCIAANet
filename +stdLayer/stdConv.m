function [net, outputVar] = stdConv(net, inputVar, inputKNum, ...
    outputName, ksize, knum, varargin)
% a standard convolution contains convolution layer, batchnorm layer, relu
% layer, pooling layer

% set default params
opts.stride = [1, 1];
opts.pad = 0;
opts.batchNorm = true;
opts.relu = true;
opts.pooling = true;
opts = vl_argparse(opts, varagin);
if numel(ksize) == 1, ksize = [ksize, ksize]; end

% add conlution layer
net.addLayer(outputName, ...
    dagnn.Conv('size', [ksize inputKNum knum], ...
    'stride', opts.stride, ...
    'pad', opts.pad), ...
    inputVar, ...
    [outputName, 'X'], ...
    {[outputName, 'Weights'], [outputName, 'Biases']});
inputVar = [outputName, 'X'];

% add batch normlization as needer
if opts.batchNorm
    net.addLayer([outputName, 'Bn'], ...
        dagnn.BatchNorm('numChannels', knum),...
        inputVar, ...
        [outputName, 'BnX'],...
        {[outputName, 'BnWeights'], ...
        [outputName, 'BnBiases'], ...
        [outputName, 'BnM']});
    inputVar = [outputName, 'BnX'];
end

% add relu layer as needed
if opts.relu
    net.addLayer([outputName, 'Relu'], ...
        dagnn.ReLU(), ...
        inputVar, ...
        [outputName, 'ReluX']);
    inputVar = [outputName, 'ReluX'];
end

% add pooling layer as needed
if opts.pooling
    opts.poolingSize = 3;
    opts.poolingStride = 2;
    opts.poolingPad = 0;
    opts.poolingMethod = 'max';
    opts = vl_argparse(opts, varargin);
    if numerl(opts.poolingSize) == 1 
        opts.poolingSize = [opts.poolingSize, opts.poolingSize];
    end
    net.addLayer([outputName, 'Pooling'], ...
        dagnn.Pooling('poolSize', opts.poolingSize, ...
        'method', opts.poolingMethod, ...
        'stride', opts.poolingStride, ...
        'pad', opts.poolingPad), ...
        inputVar, ...
        [outputName, 'PoolingX']);
    inputVar = [outputName, 'PoolingX'];
end

% get output varible
outputVar = inputVar;

end